{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Zipfile in Resources and write the contents to the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the zip file\n",
    "with zipfile.ZipFile('Resources/dot-airline-on-time-performance-statistics.zip', 'r') as zip_ref:\n",
    "    # Extract all the contents into the extraction directory\n",
    "    zip_ref.extractall('Resources')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airports Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the airports data into a Pandas DataFrame\n",
    "airports_df = pd.read_csv('Resources/dot-airline-on-time-performance-statistics/Airports')\n",
    "airports_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split Description column on the colon\n",
    "def splits1(x):\n",
    "    return pd.Series(x.split(\":\", 1))\n",
    "\n",
    "# apply the function\n",
    "airports_df[['Location', 'Airport_Name']] = airports_df['Description'].apply(splits1)\n",
    "airports_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split Location column on the comma\n",
    "def splits2(x):\n",
    "    return pd.Series(x.split(\",\", 1))\n",
    "\n",
    "# apply the function\n",
    "airports_df[['City', 'State']] = airports_df['Location'].apply(splits2)\n",
    "airports_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping old columns\n",
    "airports_df.drop(columns=[\"Description\", \"Location\"], inplace=True)\n",
    "airports_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null value\n",
    "airports_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate it dropped\n",
    "airports_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix column name formatting and correct State to location\n",
    "airports_df.rename(columns={\"Code\": \"code\", \"Airport_Name\": \"airport_name\", \"City\": \"city\", \"State\": \"location\"},inplace=True,)\n",
    "airports_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types for database entry\n",
    "airports_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV for upload to database\n",
    "filepath = Path('./Updated_CSVs/airports.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "airports_df.to_csv(filepath, index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Carriers Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Air Carriers Data into pandas dataframe\n",
    "aircarriers_df = pd.read_csv('Resources/dot-airline-on-time-performance-statistics/Air Carriers')\n",
    "aircarriers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split Description column on the colon\n",
    "def splits3(x):\n",
    "    return pd.Series(x.split(\": \", 1))\n",
    "\n",
    "# apply the function\n",
    "aircarriers_df[['Company', 'Prefix']] = aircarriers_df['Description'].apply(splits3)\n",
    "aircarriers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping old columns\n",
    "aircarriers_df.drop(columns=[\"Description\"], inplace=True)\n",
    "aircarriers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix column name formatting\n",
    "aircarriers_df.rename(columns={\"Code\": \"code\", \"Company\": \"company\", \"Prefix\": \"prefix\"},inplace=True,)\n",
    "aircarriers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types for database entry\n",
    "aircarriers_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV for upload to database\n",
    "filepath2 = Path('./Updated_CSVs/aircarriers.csv')  \n",
    "filepath2.parent.mkdir(parents=True, exist_ok=True)  \n",
    "aircarriers_df.to_csv(filepath2, index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# August 2018 Nationwide Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Airline Performance Nationwide Stats for August 2018\n",
    "aug2018_df = pd.read_csv('Resources/dot-airline-on-time-performance-statistics/August 2018 Nationwide.csv')\n",
    "aug2018_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug2018_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop\n",
    "# TAIL_NUM, ORIGIN_AIRPORT_ID, ORIGIN_AIRPORT_SEQ_ID, ORIGIN_CITY_MARKET_ID, DEST_AIRPORT_ID, DEST_AIRPORT_SEQ_ID, DEST_CITY_MARKET_ID, DEP_DELAY_NEW, ARR_DELAY_NEW, CANCELLATION_CODE, CRS_ELAPSED_TIME, ACTUAL_ELAPSED_TIME, Unnamed: 28\n",
    "\n",
    "# Keep\n",
    "# 'FL_DATE', 'OP_CARRIER_AIRLINE_ID', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST', 'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'ARR_TIME', 'ARR_DELAY', 'CANCELLED', 'CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY'\n",
    "\n",
    "# NAS - National Airspace System\n",
    "# CRS - Computer Reservation System\n",
    "\n",
    "#  FL_DATE change to datetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dataframe with the needed columns\n",
    "newaug2018_df = aug2018_df[['FL_DATE', 'OP_CARRIER_AIRLINE_ID', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST', 'CRS_DEP_TIME', 'DEP_TIME',\n",
    "                            'DEP_DELAY', 'ARR_TIME', 'ARR_DELAY', 'CANCELLED', 'CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY']].copy()\n",
    "newaug2018_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udpate colums to all lowercase to match the other dataframes\n",
    "newaug2018_df.columns = newaug2018_df.columns.str.lower()\n",
    "newaug2018_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add index column header and start index at 1\n",
    "newaug2018_df.index.name='id'\n",
    "newaug2018_df.index = np.arange(1, len(newaug2018_df) + 1)\n",
    "newaug2018_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking data types\n",
    "newaug2018_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the date column to datetime\n",
    "newaug2018_df['fl_date'] = pd.to_datetime(newaug2018_df['fl_date'])\n",
    "newaug2018_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in empty spaces with zeros\n",
    "newaug2018_df['dep_time'] = newaug2018_df['dep_time'].fillna(0)\n",
    "newaug2018_df['dep_delay'] = newaug2018_df['dep_delay'].fillna(0)\n",
    "newaug2018_df['arr_time'] = newaug2018_df['arr_time'].fillna(0)\n",
    "newaug2018_df['arr_delay'] = newaug2018_df['arr_delay'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update columns to integers\n",
    "newaug2018_df['dep_time'] = pd.to_numeric(newaug2018_df['dep_time'], downcast ='signed')\n",
    "newaug2018_df['dep_delay'] = pd.to_numeric(newaug2018_df['dep_delay'], downcast ='signed')\n",
    "newaug2018_df['arr_time'] = pd.to_numeric(newaug2018_df['arr_time'], downcast ='signed')\n",
    "newaug2018_df['arr_delay'] = pd.to_numeric(newaug2018_df['arr_delay'], downcast ='signed')\n",
    "newaug2018_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV for upload to database\n",
    "filepath3 = Path('./Updated_CSVs/aug2018.csv')  \n",
    "filepath3.parent.mkdir(parents=True, exist_ok=True)  \n",
    "newaug2018_df.to_csv(filepath3)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
